{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo --quiet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import copy, sys, os, pickle\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torchinfo import summary\n",
        "from torch import optim\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ],
      "metadata": {
        "id": "GLsoG1MvpRoi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "Dric-eI7F5Ww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_data = datasets.MNIST(root=\"./\", download=True, transform=transforms.ToTensor())\n",
        "mnist_trainset, mnist_testset = train_test_split(mnist_data, test_size=0.1, random_state=42)\n",
        "\n",
        "train_loader_mnist = torch.utils.data.DataLoader(mnist_trainset, batch_size=64, shuffle=True)\n",
        "testloader_mnist = torch.utils.data.DataLoader(mnist_testset, batch_size=1000, shuffle=False)\n",
        "n_classes = 10"
      ],
      "metadata": {
        "id": "ivoLTkBQFk6h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f182502-448d-4280-ea5a-070f73fc5e3b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 17085854.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 469858.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 4268012.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4093366.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def download_file(id):\n",
        "  response = requests.get(id)\n",
        "  with BytesIO(response.content) as file:\n",
        "    return pickle.load(file)\n",
        "\n",
        "dropbox_url = 'https://www.dropbox.com/scl/fi/zagdv3cdcdpovq7q7f2qy/train_cifar.pickle?rlkey=l9vnwmqdcflqco9dy9pjgmw2v&st=kypisxmq&raw=1'\n",
        "train_files_download = download_file(dropbox_url)\n",
        "dropbox_url = 'https://www.dropbox.com/scl/fi/g6i500yd1ma8hkheirev9/test_cifar.pickle?rlkey=toj5pf2g9u87bcllzihv4j5ov&st=xm5kspi1&raw=1'\n",
        "test_files_download = download_file(dropbox_url)\n",
        "\n",
        "train_files = train_files_download['data']\n",
        "label_list = train_files_download['labels']\n",
        "val_files = test_files_download['data']\n",
        "val_list = test_files_download['labels']"
      ],
      "metadata": {
        "id": "9DUJfstPFunh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MNIST digits classification - Simple convnet"
      ],
      "metadata": {
        "id": "PpOt6lRuJ7sA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST digits - Load a sample 7"
      ],
      "metadata": {
        "id": "2soYlg_aQzng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_sample_7 , label_sample = mnist_trainset[next((i for i, (image, label) in enumerate(mnist_trainset) if label == 7), None)]\n",
        "\n",
        "# Convert tensor to numpy array and plot the image\n",
        "plt.imshow(image_sample_7.squeeze().numpy(), cmap='gray')\n",
        "plt.title('Image of the number 7')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1-TCJBk-CRWS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "477450a0-19fe-4c9a-fdb1-a43ab9330258"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define model"
      ],
      "metadata": {
        "id": "yQjW5BsSKYQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCNN2(nn.Module):        # The model is defined by defining the class\n",
        "    def __init__(self, n_classes):\n",
        "        super(MyCNN2, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            #  (𝑁 batch size,𝐶in,𝐻,𝑊)\n",
        "            nn.Conv2d(in_channels= 1, out_channels = 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features = 7*7*32, out_features = n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n"
      ],
      "metadata": {
        "id": "CvAzhFD2EgGE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model"
      ],
      "metadata": {
        "id": "fbqr59cAKbIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_s = MyCNN2(n_classes)        # model is an intance of the class\n",
        "alpha_s, n_epochs_s = 1e-2, 3\n",
        "# Loss and optimizer\n",
        "criterion_s = nn.CrossEntropyLoss()\n",
        "optimizer_s = torch.optim.Adam(model_s.parameters(), lr = alpha_s)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(n_epochs_s):\n",
        "    for images, labels_s in train_loader_mnist:\n",
        "        outputs_s = model_s(images)\n",
        "        #loss = F.cross_entropy(outputs, labels)\n",
        "        loss_s = criterion_s(outputs_s, labels_s)\n",
        "        optimizer_s.zero_grad()\n",
        "        loss_s.backward()\n",
        "        optimizer_s.step()\n",
        "    print(f'Epoch [{epoch+1}/{n_epochs_s}], Loss: {round(loss_s.item(), 4)}')"
      ],
      "metadata": {
        "id": "YV9sburtEhIg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4409649-d087-46a2-c331-39b63fb3c896"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Loss: 0.0596\n",
            "Epoch [2/3], Loss: 0.0445\n",
            "Epoch [3/3], Loss: 0.0029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_s.eval()\n",
        "with torch.no_grad():\n",
        "    output_s = model_s(image_sample_7.unsqueeze(0)) # Adds a new dimension of size 1 at specified position\n",
        "    _, predicted = torch.max(output_s, 1)\n",
        "predicted"
      ],
      "metadata": {
        "id": "SaLuFAoUCnOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10bc27dc-634f-4ee6-bf34-c0a1747a67b0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display NN layers"
      ],
      "metadata": {
        "id": "UHYhqYoYGDZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model_s, input_data=torch.zeros((5, 1, 28, 28)))"
      ],
      "metadata": {
        "id": "1wVf4L-KZeHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a95a55a2-af24-44fc-a3b4-723450598a94"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "MyCNN2                                   [5, 10]                   --\n",
              "├─Sequential: 1-1                        [5, 10]                   --\n",
              "│    └─Conv2d: 2-1                       [5, 16, 28, 28]           416\n",
              "│    └─ReLU: 2-2                         [5, 16, 28, 28]           --\n",
              "│    └─MaxPool2d: 2-3                    [5, 16, 14, 14]           --\n",
              "│    └─Conv2d: 2-4                       [5, 32, 14, 14]           12,832\n",
              "│    └─ReLU: 2-5                         [5, 32, 14, 14]           --\n",
              "│    └─MaxPool2d: 2-6                    [5, 32, 7, 7]             --\n",
              "│    └─Flatten: 2-7                      [5, 1568]                 --\n",
              "│    └─Linear: 2-8                       [5, 10]                   15,690\n",
              "==========================================================================================\n",
              "Total params: 28,938\n",
              "Trainable params: 28,938\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 14.28\n",
              "==========================================================================================\n",
              "Input size (MB): 0.02\n",
              "Forward/backward pass size (MB): 0.75\n",
              "Params size (MB): 0.12\n",
              "Estimated Total Size (MB): 0.88\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "m2iP-dp0x98o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now evaluate our trained model on the test data. We first call torch.no_grad() to disable gradient computation to save memory and runtime. This is useful when we are only doing inference and do not update the model.\n",
        "\n"
      ],
      "metadata": {
        "id": "_D0pW2ABEpp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# label_list = []\n",
        "# predicted_list = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in testloader_mnist:\n",
        "        outputs = model_s(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        #breakpoint()\n",
        "    print(f'Test Accuracy of the model on the 10000 test images: {100 * correct / total}')"
      ],
      "metadata": {
        "id": "fjUcuKwxEqLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30034e6a-7416-4096-e53e-34ef3afc55cd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 97.51666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LeNet"
      ],
      "metadata": {
        "id": "aCgWYtLOM0BQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define model"
      ],
      "metadata": {
        "id": "6APd2l6Wf2iI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        \"\"\"\n",
        "        args:\n",
        "            input_dim (Tuple): the shape (n_channels, height, width) of a sample data point\n",
        "            output_dim (int): the number of nodes in the output layer\n",
        "        \"\"\"\n",
        "        super(LeNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(input_dim[0], 6, kernel_size=5, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "            nn.Flatten(1),\n",
        "            nn.Linear(400, 120),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(120, 84),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84, output_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer1(x)\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(input_dim[0], 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "            nn.Conv2d(64, 192, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "            nn.Dropout()\n",
        "            ,nn.Flatten(1)\n",
        "            ,nn.Linear(1024, 4096)\n",
        "            ,nn.ReLU(inplace = True)\n",
        "            ,nn.Dropout()\n",
        "            ,nn.Linear(4096, 1024)\n",
        "            ,nn.ReLU(inplace = True)\n",
        "            ,nn.Linear(1024, output_dim)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.layer1(x)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "AzmlH5Mm3kZ2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define training"
      ],
      "metadata": {
        "id": "o2OTTrequQAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, n_epochs, train_loader, val_loader, optimizer, scheduler = None, verbose = False, filepath=None, device='cpu'):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    print(device)\n",
        "\n",
        "    train_accuracy = []; train_loss = []; val_accuracy = []; val_loss = []\n",
        "    best_acc = 0\n",
        "    best_model_loop = 1\n",
        "\n",
        "    for i in range(n_epochs):\n",
        "\n",
        "        losses = []\n",
        "        total = 0\n",
        "        matches = 0\n",
        "\n",
        "        model.train()                                       # Set your model to training mode\n",
        "\n",
        "        for X, y in train_loader:                           # Iterate over all samples by minibatches\n",
        "            X, y = X.to(device), y.to(device)               # Set tensors to GPU if available\n",
        "            outputs = model(X)\n",
        "\n",
        "            loss = F.cross_entropy(outputs, y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            #breakpoint()\n",
        "            y_hat = torch.argmax(outputs, axis = 1)         # Index with highest prob = prediction\n",
        "\n",
        "            matches = matches + ((y==y_hat).sum()).item()   # Keep count of correct matches during training\n",
        "            total = total + y.size(0)                       # Keep count of total number of samples during training\n",
        "            losses.append(loss.item())\n",
        "\n",
        "        # The average training loss is defined as the sum of loss values across all minibatches, divided by the number of minibatches.\n",
        "        # print(f'Average TRAINING accuracy across in epoch: {i}', (matches/total))\n",
        "\n",
        "        # The average training accuracy is defined as the sum of correct matches across all minibatches, divided by the number of minibatches.\n",
        "        train_acc=matches/total\n",
        "        train_loss.append(np.mean(losses))\n",
        "        train_accuracy.append(train_acc)\n",
        "        print('Tr: ', round(train_acc,2), end=' ')\n",
        "\n",
        "        # used to dynamically adjust the learning rate during training. Should be called once every epoch after all the training iterations in that epoch have finished.\n",
        "        if scheduler is not None: scheduler.step()\n",
        "\n",
        "        matches = 0\n",
        "        total = 0\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "          for X, y in val_loader:\n",
        "              X, y = X.to(device), y.to(device)\n",
        "\n",
        "              outputs = model(X)\n",
        "              y_hat = torch.argmax(outputs, axis = 1)\n",
        "\n",
        "              matches = matches + ((y==y_hat).sum()).item()\n",
        "              total = total + y.size(0)\n",
        "\n",
        "          val_accuracy.append(matches/total)\n",
        "\n",
        "          if (best_acc < matches/total):\n",
        "              best_acc = matches/total\n",
        "              best_model_loop = i+1\n",
        "              best_model = copy.deepcopy(model)\n",
        "\n",
        "        test_acc = matches/total\n",
        "        print('Te: ', round(test_acc,2), end=' ')\n",
        "\n",
        "\n",
        "    if filepath is not None:\n",
        "        torch.save(best_model.state_dict(), filepath)\n",
        "\n",
        "    return (best_model, best_model_loop, train_accuracy, train_loss, val_accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "A76lJAPT-JGW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Dataset and DataLoader"
      ],
      "metadata": {
        "id": "kkcQVuNbi2hQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data_dict, label_list):\n",
        "        # self.data is a container for the dataset, which should be a 4D Numpy array of shape (n_images, height, width, n_channels).\n",
        "        self.data = data_dict.reshape(-1, 32, 32, 3)\n",
        "        self.labels = label_list\n",
        "\n",
        "    def __len__(self): return(len(self.labels))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((.5, .5, .5),(.5,.5, .5))])\n",
        "\n",
        "        tensor = transform(self.data[idx])\n",
        "        dlabel = self.labels[idx]\n",
        "\n",
        "        return (tensor, dlabel)\n",
        "\n",
        "# Create a dataloader\n",
        "def get_dataloader(trainset, valset = None, batch_size = 64, num_workers = 2):\n",
        "\n",
        "    train = DataLoader(dataset = trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    val = DataLoader(dataset = valset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "    return train, val\n"
      ],
      "metadata": {
        "id": "_h0F204bm3Vw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_trainset = ImageDataset(train_files, label_list)\n",
        "full_valset = ImageDataset(val_files, val_list)\n"
      ],
      "metadata": {
        "id": "kzo61vJ53QUz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim, output_dim = (3, 32, 32), 10\n",
        "\n",
        "# hyperparameters\n",
        "lr = 0.001\n",
        "weight_decay = 5e-4\n",
        "batch_size = 128\n",
        "n_epochs = 30\n",
        "scheduler = None\n",
        "\n",
        "model = AlexNet(input_dim, output_dim)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay = weight_decay)\n",
        "train_loader, val_loader = get_dataloader(full_trainset, full_valset, batch_size=batch_size)\n",
        "\n",
        "#scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lambda epoch: 0.95 * epoch)\n",
        "best_model, best_acc_epoch_num, train_accs, train_losses, val_accs = train_model(model, n_epochs, train_loader, val_loader, optimizer, scheduler=scheduler, verbose = False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asfXZALyKamH",
        "outputId": "6fcd9ae7-fdd2-4146-e647-bfdae54cadc2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Tr:  0.25 Te:  0.36 Tr:  0.4 Te:  0.44 Tr:  0.47 Te:  0.5 Tr:  0.51 Te:  0.53 Tr:  0.54 Te:  0.55 Tr:  0.57 Te:  0.55 Tr:  0.58 Te:  0.57 Tr:  0.6 Te:  0.58 Tr:  0.62 Te:  0.56 Tr:  0.63 Te:  0.59 Tr:  0.64 Te:  0.59 Tr:  0.65 Te:  0.58 Tr:  0.66 Te:  0.58 Tr:  0.67 Te:  0.6 Tr:  0.68 Te:  0.59 Tr:  0.69 Te:  0.59 Tr:  0.7 Te:  0.6 Tr:  0.71 Te:  0.58 Tr:  0.72 Te:  0.59 Tr:  0.73 Te:  0.6 Tr:  0.74 Te:  0.6 Tr:  0.75 Te:  0.58 Tr:  0.75 Te:  0.6 Tr:  0.76 Te:  0.6 Tr:  0.77 Te:  0.6 Tr:  0.78 Te:  0.59 Tr:  0.78 Te:  0.6 Tr:  0.79 Te:  0.59 Tr:  0.79 Te:  0.58 Tr:  0.8 Te:  0.59 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=list(range(1,n_epochs)), y=train_accs,\n",
        "                    mode='lines',\n",
        "                    name='train_accs'))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=list(range(1,n_epochs)), y=val_accs,\n",
        "                    mode='lines',\n",
        "                    name='val_accs'))\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Train and Validation Accuracy for LeNet\",\n",
        "    xaxis_title=\"Epoch\",\n",
        "    yaxis_title=\"Accuracy\",\n",
        "    font=dict(\n",
        "        family=\"Arial\",\n",
        "        size=16,\n",
        "        color=\"Black\"\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "vd4vlfFLC1nL",
        "outputId": "b588b3fa-49f1-4a8f-8ad2-8b8061fa67c9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"ff5fb29a-ddf3-4f85-aa10-1dfec4df888c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ff5fb29a-ddf3-4f85-aa10-1dfec4df888c\")) {                    Plotly.newPlot(                        \"ff5fb29a-ddf3-4f85-aa10-1dfec4df888c\",                        [{\"mode\":\"lines\",\"name\":\"train_accs\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"y\":[0.24664,0.39576,0.466,0.50984,0.54224,0.56626,0.58372,0.60062,0.61636,0.62852,0.64284,0.65388,0.6633,0.67412,0.68276,0.69238,0.70274,0.71206,0.71934,0.7291,0.73838,0.74662,0.75134,0.75984,0.76926,0.77592,0.78018,0.78838,0.78892,0.80268],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"val_accs\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"y\":[0.3555,0.44,0.5035,0.5277,0.5506,0.5538,0.5714,0.585,0.5585,0.5905,0.5942,0.5831,0.5779,0.5955,0.5938,0.588,0.599,0.5799,0.5883,0.5959,0.5981,0.5839,0.5957,0.5985,0.5967,0.5915,0.5976,0.5943,0.5839,0.5894],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"font\":{\"family\":\"Arial\",\"size\":16,\"color\":\"Black\"},\"title\":{\"text\":\"Train and Validation Accuracy for LeNet\"},\"xaxis\":{\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"title\":{\"text\":\"Accuracy\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ff5fb29a-ddf3-4f85-aa10-1dfec4df888c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test accuracy doesnt improve after 10 epochs while it continues to increase for training suggesting overfitting.  Learning rates and weight decay can be adjusted to improve out of sample accuracy"
      ],
      "metadata": {
        "id": "EcyiTrEIlDq3"
      }
    }
  ]
}